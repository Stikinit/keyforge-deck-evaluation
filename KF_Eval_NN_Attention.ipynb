{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sw6Xyl8i9uJ"
      },
      "outputs": [],
      "source": [
        "!pip install --user -q seaborn\n",
        "!pip install --user hyperopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0Sy0XGnFcDP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras import backend as K\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from hyperopt import fmin, tpe, hp, Trials\n",
        "from hyperopt import STATUS_OK\n",
        "from hyperopt import space_eval\n",
        "from functools import partial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VHsGlvcrWdS"
      },
      "source": [
        "Dataset loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfo71BwOFsL0"
      },
      "outputs": [],
      "source": [
        "train_df_path = './MultipleFeaturesDS/DS_CoA_Training.csv'\n",
        "test_df_path = './MultipleFeaturesDS/DS_CoA_Testing.csv'\n",
        "\n",
        "# Loads the dataset in a Pandas Dataframe\n",
        "train_df = pd.read_csv(train_df_path).sample(frac=1)\n",
        "test_df = pd.read_csv(test_df_path).sample(frac=1)\n",
        "train_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pICwVwFGIeaA"
      },
      "outputs": [],
      "source": [
        "train_df.describe().transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZOOul5PIzyQ"
      },
      "outputs": [],
      "source": [
        "train_labels = train_df.pop('sas_rating')\n",
        "test_labels = test_df.pop('sas_rating')\n",
        "\n",
        "# Convert the dataframe into a TendorFlow Dataset\n",
        "#train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=\"sas_rating\", task=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfgPWtY7owtr"
      },
      "outputs": [],
      "source": [
        "def input_setup(df):\n",
        "  df_houses = df.iloc[:, 0:7]\n",
        "  df_type_counts = df.iloc[:, 799:804]\n",
        "  df_deck = pd.concat([df_houses, df_type_counts], axis=1)\n",
        "\n",
        "  df_cards = df.drop(df_houses, axis=1)\n",
        "  df_cards.drop(df_type_counts, axis=1, inplace=True)\n",
        "\n",
        "  tensor_cards = tf.convert_to_tensor(df_cards)\n",
        "  tensor_cards = tf.reshape(tensor_cards, (len(df_cards), 36, 22))\n",
        "\n",
        "  return [tensor_cards, df_deck]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI6Yx4KOKp8C"
      },
      "source": [
        "# Building the **Keras Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSnq1HRUP1na"
      },
      "source": [
        "Prepare **hyperparameters** using Hyperopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7xh5GBxP2Ha"
      },
      "outputs": [],
      "source": [
        "# Define the HPs\n",
        "search_space = {\n",
        "  'dense_a_size': hp.choice('dense_a_size', np.arange(0, 100, 10)),\n",
        "  'dense_b_size': hp.choice('dense_b_size', np.arange(0, 100, 10)),\n",
        "  'dense_one_size': hp.choice('dense_one_size', np.arange(0, 100, 10)),\n",
        "  'dense_two_size': hp.choice('dense_two_size', np.arange(0, 100, 10)),\n",
        "  'dropout_b_rate': hp.uniform('dropout_b_rate', 0.0, 0.3),\n",
        "  'dropout_one_rate': hp.uniform('dropout_one_rate', 0.0, 0.3),\n",
        "  'dropout_two_rate': hp.uniform('dropout_two_rate', 0.0, 0.3),\n",
        "  'opt_learning_rate': hp.loguniform('opt_learning_rate', -10, 0)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2tvfMosYa5C"
      },
      "outputs": [],
      "source": [
        "class WeightedSumByDotProduct(keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(WeightedSumByDotProduct, self).__init__()\n",
        "\n",
        "    def call(self, info, a):\n",
        "        return K.batch_dot(info, a, axes=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGaFiQEwKpff"
      },
      "outputs": [],
      "source": [
        "def build_and_compile_model(params):\n",
        "\n",
        "  # Setup model branches\n",
        "  input_card_info = layers.Input(shape=(36,22))\n",
        "  input_deck_info = layers.Input(shape=(11,))\n",
        "\n",
        "  # Branch A (card info)\n",
        "  dense_layer = layers.Dense(params['dense_a_size'], activation='relu')\n",
        "  a = layers.TimeDistributed(dense_layer)(input_card_info)\n",
        "  single_dense_layer = layers.Dense(1)\n",
        "  a = layers.TimeDistributed(single_dense_layer)(a)\n",
        "  a = layers.Flatten()(a)\n",
        "  a = layers.Softmax()(a)\n",
        "  a = WeightedSumByDotProduct()(input_card_info, a)\n",
        "  a = keras.models.Model(inputs=input_card_info, outputs=a)\n",
        "\n",
        "  # Branch B (deck info)\n",
        "  b = layers.Dense(params['dense_b_size'], activation='relu')(input_deck_info)\n",
        "  b = layers.Dropout(params['dropout_b_rate'])(b)\n",
        "  b = keras.models.Model(inputs=input_deck_info, outputs=b)\n",
        "\n",
        "  # Concat the 2 outputs\n",
        "  combined = layers.concatenate([a.output, b.output])\n",
        "\n",
        "  # Last layers of final Model\n",
        "  z = layers.Dense(params['dense_one_size'], activation='relu')(combined)\n",
        "  z = layers.Dropout(params['dropout_one_rate'])(z)\n",
        "  z = layers.Dense(params['dense_two_size'], activation='relu')(z)\n",
        "  z = layers.Dropout(params['dropout_two_rate'])(z)\n",
        "  z = layers.Dense(1)(z)\n",
        "\n",
        "  model = keras.models.Model(inputs=[a.input, b.input], outputs=z)\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(params['opt_learning_rate'])\n",
        "  model.compile(loss='mae', optimizer=optimizer, metrics=['mae','mse'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZy-cP1WPBu1"
      },
      "source": [
        "# **HyperParameter** optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGVuiK7HPbqD"
      },
      "outputs": [],
      "source": [
        "def train_fcn(params, verbose=0):  \n",
        "  model = build_and_compile_model(params)\n",
        "  if verbose == 1: model.summary()\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "  history = model.fit(\n",
        "      input_setup(train_df), train_labels, \n",
        "      epochs=200,\n",
        "      # Calculate validation results on 20% of the training data\n",
        "      validation_split = 0.2,\n",
        "      callbacks=[early_stopping], verbose=verbose)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbciPYvQZKTa"
      },
      "outputs": [],
      "source": [
        "def test_fcn(model):\n",
        "  loss, mae, mse = model.evaluate(input_setup(test_df), test_labels, verbose=0)\n",
        "  return mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x82GddPjZRJ6"
      },
      "outputs": [],
      "source": [
        "def hyperopt_fcn(params):\n",
        "  model = train_fcn(params)\n",
        "  mae = test_fcn(model)\n",
        "  K.clear_session()\n",
        "  return {'loss': mae, 'status': STATUS_OK}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q0S9KGyZjm1"
      },
      "source": [
        "**Optimize** the **model**, while keeping track of the best results with a trials file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAKiSFhEbwGr"
      },
      "outputs": [],
      "source": [
        "trials_folder = './Trials'\n",
        "model_name = 'kfe_model'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4qIIGLiZjMy"
      },
      "outputs": [],
      "source": [
        "def run_trials():\n",
        "\n",
        "    trials_step = 1  # how many additional trials to do after loading saved trials. 1 = save after iteration\n",
        "    max_trials = 11  # initial max_trials. > N because of the initial random iterations of fmin ( N = 16 (default is 20))\n",
        "\n",
        "    \n",
        "    try:  # try to load an already saved trials object, and increase the max\n",
        "        trials = pickle.load(open(trials_folder + model_name + \".hyperopt\", \"rb\"))\n",
        "        print(\"Found saved Trials! Loading...\")\n",
        "        max_trials = len(trials.trials) + trials_step\n",
        "        print(\"Rerunning from {} trials to {} (+{}) trials\".format(len(trials.trials), max_trials, trials_step))\n",
        "    except:  # create a new trials object and start searching\n",
        "        trials = Trials()\n",
        "\n",
        "    best = fmin(hyperopt_fcn, search_space, algo=partial(tpe.suggest, n_startup_jobs=10), max_evals=max_trials, trials=trials)\n",
        "\n",
        "    print(\"Best:\", best)\n",
        "    \n",
        "    # save the trials object\n",
        "    with open(trials_folder + model_name + \".hyperopt\", \"wb\") as f:\n",
        "        pickle.dump(trials, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cVGzc84aIBn"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "  run_trials()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmLcxJJmaL-M"
      },
      "source": [
        "**Load** best HyperParameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9n7AWfZE526V"
      },
      "outputs": [],
      "source": [
        "def unpack_hyperopt_vals(vals):\n",
        "    \"\"\"\n",
        "    Unpack values from a hyperopt return dictionary where values are wrapped in a list.\n",
        "    :param vals: dict\n",
        "    :return: dict\n",
        "        copy of the dictionary with unpacked values\n",
        "    \"\"\"\n",
        "    assert isinstance(vals, dict), \"Parameter must be given as dict.\"\n",
        "    ret = {}\n",
        "    for k, v in list(vals.items()):\n",
        "        try:\n",
        "            ret[k] = v[0]\n",
        "        except (TypeError, IndexError):\n",
        "            ret[k] = v\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0UnVdvd5Zu1",
        "outputId": "2d79ad31-e477-4fc4-ef70-07c04082497a"
      },
      "outputs": [],
      "source": [
        "trials = pickle.load(open(trials_folder + model_name + \".hyperopt\", \"rb\"))\n",
        "best = unpack_hyperopt_vals(trials.best_trial.get('misc').get('vals'))\n",
        "opt_params = space_eval(search_space, best)\n",
        "opt_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3VChMikb993"
      },
      "source": [
        "# **Train** the final model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4Qn6tTicFZV",
        "outputId": "a7da299c-5eb7-4e91-ed51-c0b2387abd34"
      },
      "outputs": [],
      "source": [
        "min_mae = 3.80\n",
        "while True:\n",
        "  model = train_fcn(opt_params)\n",
        "  mae = test_fcn(model)\n",
        "  print(mae)\n",
        "\n",
        "  if mae < min_mae:\n",
        "    model.save(\"./Model/KF_Eval_model\")\n",
        "    min_mae = mae\n",
        "\n",
        "  if (mae <= 3.68): break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HigWhoNocui-"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\"./Model/KF_Eval_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPzE96h8SOB-"
      },
      "source": [
        "Visualize the **loss** and **val_loss** of the model, for tesing porpouses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHH9RandTONr"
      },
      "outputs": [],
      "source": [
        "loss, mae, mse = model.evaluate(input_setup(test_df), test_labels, verbose=0)\n",
        "print(\"Mean Abs Error: {:5.2f} SAS points\".format(mae))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTfTzRT4UBFD"
      },
      "source": [
        "# **Testing** the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URJRpN4AW5Ag"
      },
      "source": [
        "**Result** visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DpxnTqnbUF5U",
        "outputId": "8f386a5d-7c10-4ab1-c85e-3886bce29c86"
      },
      "outputs": [],
      "source": [
        "test_predictions = model.predict(input_setup(test_df)).flatten()\n",
        "sampled_predictions = model.predict(input_setup(test_df.sample(1000, random_state=420)))\n",
        "sampled_labels = test_labels.sample(1000, random_state=420)\n",
        "\n",
        "correct = 0\n",
        "for truth, prediction in zip(test_labels.to_numpy(), test_predictions):\n",
        "  if truth in range(int(prediction-5), int(prediction+6)):\n",
        "    correct+=1\n",
        "print(\"Accuracy (-5;+5): {:5.2f}\\n\".format(correct/len(test_labels)))\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [16, 12]\n",
        "plt.rcParams['figure.dpi'] = 100 \n",
        "\n",
        "plt.scatter(sampled_labels, sampled_predictions)\n",
        "plt.xlabel('True Values [SAS]')\n",
        "plt.ylabel('Predictions [SAS]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([35, plt.xlim()[1]])\n",
        "plt.ylim([35, plt.ylim()[1]])\n",
        "_ = plt.plot([-100, 100], [-100, 100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXmaQAhPYEAz"
      },
      "source": [
        "**Error** visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "id": "d_BgV16UYJ6u",
        "outputId": "7b5da47a-58ff-47e2-e6d5-be263cf72602"
      },
      "outputs": [],
      "source": [
        "error = test_predictions - test_labels\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error [SAS]\")\n",
        "_ = plt.ylabel(\"Count\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YxsftTLZLNo"
      },
      "source": [
        "**Error** distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fsz2f9QaZOXt",
        "outputId": "4c7257de-b445-4645-fa88-61c83eae67d3"
      },
      "outputs": [],
      "source": [
        "sampled_error = error.sample(1000, random_state=420)\n",
        "\n",
        "plt.scatter(sampled_labels, sampled_error)\n",
        "plt.axhline(y=10)\n",
        "plt.axhline(y=5)\n",
        "plt.axhline(y=-5)\n",
        "plt.axhline(y=-10)\n",
        "plt.xlabel('True Values [SAS]')\n",
        "plt.ylabel('Error [SAS]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JXrtIExn-Kl"
      },
      "source": [
        "# **Accuracy** stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWwxNPJgoEwH"
      },
      "source": [
        "**Accuracy** based on range percentages with 10 **categories**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ2-ibcioEWZ",
        "outputId": "6733a777-58fc-41f3-bf77-addc97125945"
      },
      "outputs": [],
      "source": [
        "category_dfs = [pd.DataFrame(columns=test_df.columns),pd.DataFrame(columns=test_df.columns),pd.DataFrame(columns=test_df.columns),pd.DataFrame(columns=test_df.columns),\n",
        "                pd.DataFrame(columns=test_df.columns),pd.DataFrame(columns=test_df.columns),pd.DataFrame(columns=test_df.columns),pd.DataFrame(columns=test_df.columns),\n",
        "                pd.DataFrame(columns=test_df.columns),pd.DataFrame(columns=test_df.columns)]\n",
        "category_truths = [[], [], [], [], [], [], [], [], [], []]\n",
        "\n",
        "res_test_labels = test_labels.reset_index(drop=True)\n",
        "res_test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "for i, sas in res_test_labels.iteritems():\n",
        "  if sas <= 42:\n",
        "    category_dfs[0] = category_dfs[0].append(res_test_df.iloc[i])\n",
        "    category_truths[0].append(sas)\n",
        "  elif sas in range(43,49):\n",
        "    category_dfs[1] = category_dfs[1].append(res_test_df.iloc[i])\n",
        "    category_truths[1].append(sas)\n",
        "  elif sas in range(49,55):\n",
        "    category_dfs[2] = category_dfs[2].append(res_test_df.iloc[i])\n",
        "    category_truths[2].append(sas)\n",
        "  elif sas in range(55,61):\n",
        "    category_dfs[3] = category_dfs[3].append(res_test_df.iloc[i])\n",
        "    category_truths[3].append(sas)\n",
        "  elif sas in range(61,67):\n",
        "    category_dfs[4] = category_dfs[4].append(res_test_df.iloc[i])\n",
        "    category_truths[4].append(sas)\n",
        "  elif sas in range(67,73):\n",
        "    category_dfs[5] = category_dfs[5].append(res_test_df.iloc[i])\n",
        "    category_truths[5].append(sas)\n",
        "  elif sas in range(73,79):\n",
        "    category_dfs[6] = category_dfs[6].append(res_test_df.iloc[i])\n",
        "    category_truths[6].append(sas)\n",
        "  elif sas in range(79,85):\n",
        "    category_dfs[7] = category_dfs[7].append(res_test_df.iloc[i])\n",
        "    category_truths[7].append(sas)\n",
        "  elif sas in range(85,91):\n",
        "    category_dfs[8] = category_dfs[8].append(res_test_df.iloc[i])\n",
        "    category_truths[8].append(sas)\n",
        "  elif sas >= 91:\n",
        "    category_dfs[9] = category_dfs[9].append(res_test_df.iloc[i])\n",
        "    category_truths[9].append(sas)\n",
        "\n",
        "print(\"Deck range (-5;+5) accuracies:\")\n",
        "for i, df in enumerate(category_dfs):\n",
        "  if (df.empty): continue\n",
        "  res = model.predict(input_setup(df)).flatten()\n",
        "  correct = 0\n",
        "  for idx, truth in enumerate(category_truths[i]):\n",
        "    if truth in range(int(res[idx]-5), int(res[idx]+6)):\n",
        "      correct+=1\n",
        "  print(\"Category \"+str(i+1)+\": \"+str(correct/len(category_truths[i])))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGx-0HiGwY1h"
      },
      "source": [
        "**Confusion matrix** using 10 **categories**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1B1oORHxeFn"
      },
      "outputs": [],
      "source": [
        "def categorize_sas(sas):\n",
        "  if sas <= 42:\n",
        "    return 1\n",
        "  elif sas in range(43,49):\n",
        "    return 2\n",
        "  elif sas in range(49,55):\n",
        "    return 3\n",
        "  elif sas in range(55,61):\n",
        "    return 4\n",
        "  elif sas in range(61,67):\n",
        "    return 5\n",
        "  elif sas in range(67,73):\n",
        "    return 6\n",
        "  elif sas in range(73,79):\n",
        "    return 7\n",
        "  elif sas in range(79,85):\n",
        "    return 8\n",
        "  elif sas in range(85,91):\n",
        "    return 9\n",
        "  elif sas >= 91:\n",
        "    return 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fthVswgwwYlO",
        "outputId": "5769a051-2e6c-4d80-e288-6f6783cff46e"
      },
      "outputs": [],
      "source": [
        "res_test_labels = test_labels.reset_index(drop=True)\n",
        "res_test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "test_category_labels = res_test_labels.apply(categorize_sas).tolist()\n",
        "test_predictions = model.predict(input_setup(res_test_df)).flatten().tolist()\n",
        "test_category_predictions = [categorize_sas(int(p)) for p in test_predictions]\n",
        "\n",
        "data = {\n",
        "  'y_Actual':    test_category_labels,\n",
        "  'y_Predicted': test_category_predictions \n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
        "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
        "confusion_matrix.insert(loc=0, column='1', value=[0,0,0,0,0,0,0,0,0,0])\n",
        "confusion_matrix['10'] = [0,0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [10, 8]\n",
        "plt.rcParams['figure.dpi'] = 100 \n",
        "plt.rc('axes', labelsize=15)    # fontsize of the x and y labels\n",
        "\n",
        "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='viridis')\n",
        "plt.show()\n",
        "\n",
        "confusion_matrix = confusion_matrix.apply(lambda x: x/x.sum(), axis = 1)\n",
        "sns.heatmap(confusion_matrix, annot=True, fmt='.2g', cmap='viridis')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "KF-Eval-NN-Attention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
